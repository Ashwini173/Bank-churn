# -*- coding: utf-8 -*-
"""Day5.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1MiuarvqFGXLHsGfIooyOJskmJwxXVTrS
"""

import pandas as pd
import numpy as np

df=pd.read_csv("WA_Fn-UseC_-Telco-Customer-Churn.csv",na_values=[" "],index_col=0)

df.shape

df.head

df.dtypes

df.columns

df.isnull().all

#label_map for columns string to int
label_map = { 'Dependents':{'Yes':1,'No':0},
             'PhoneService':{'Yes':1,'No':0},
             'gender':{'Female':1,'Male':0},
             'Partner':{'Yes':1,'No':0},
             'MultipleLines':{'Yes':1,'No':0,'No phone service':2},
             'InternetService':{'DSL':1,'Fiber optic':0,'No':2},
             'OnlineSecurity':{'Yes':1,'No':0,'No internet service':2},
             'OnlineBackup':{'Yes':1,'No':0,'No internet service':2},
             'DeviceProtection':{'Yes':1,'No':0,'No internet service':2},
             'TechSupport':{'Yes':1,'No':0,'No internet service':2},
             'StreamingTV':{'Yes':1,'No':0,'No internet service':2},
             'StreamingMovies':{'Yes':1,'No':0,'No internet service':2},
             'Contract':{'Month-to-month':1,'One year':1,'Two year':2},
             'PaperlessBilling':{'Yes':1,'No':0},
             'PaymentMethod':{'Electronic check':0,'Mailed check':1,'Bank transfer (automatic)':2,'Credit card (automatic)':3},
             'Churn':{'Yes':1,'No':0}}

#df = pd.get_dummies(df,drop_first=True)
#df.columns

df_1 = pd.read_csv("WA_Fn-UseC_-Telco-Customer-Churn.csv",na_values=[" "],index_col=0)
df_1 = df_1.replace(label_map)

df_1.isnull().sum()/ df_1.shape[0]

df_1.fillna(df_1.mode().iloc[0],inplace= True)

df_1.isnull().sum()/ df_1.shape[0]

#df_2 = pd.get_dummies(df_1, prefix_sep="__",
                              columns=['MultipleLines','InternetService','OnlineSecurity','OnlineBackup','DeviceProtection','TechSupport','StreamingTV',
                                       'StreamingMovies', 'Contract','PaperlessBilling','PaymentMethod','Churn','Dependents', 'PhoneService','gender',
                                      'Partner'],drop_first=True)
#df_2

df_1 = pd.get_dummies(df_1,drop_first=True)
df_1.columns

df_1.shape

df_1.dtypes

df_1['Churn'].unique()

df_1.columns.isnull()

df_1.shape,len(df_1)

#df_1 = df_1.isnull().sum()/df_1.shape[0]*100
#df_1

df_1=df_1.loc[:,df_1.columns[df_1.isnull().sum() / df_1.shape[0] < 0.9]]

df_1.dropna(axis=1, thresh=int(0.1 * df_1.shape[0]),inplace= True)

print(df_1.isnull().sum(axis=1))

df_1 = df_1[df_1.isnull().sum(axis=1) <=(df_1.shape[1] * 0.5)]

df_1.columns[df_1.isna().any()], len(df_1.columns[df_1.isna().any()])

#using mode fill NA values of rows
for col in df_1.columns[df_1.isnull().any()]:
  df_1[col].fillna(df_1[col].mode()[0],inplace=True)

df_1.columns[df_1.isnull().any()]

df_1.fillna(df_1.mode().iloc[0])

df_1.describe()

df_1.std()

df_1=df_1.loc[:, (df_1 != df_1.iloc[0]).any()]
df_1.shape

df_1.describe(include= 'all')

from sklearn import preprocessing

x = df_1.values #returns a numpy array
min_max_scaler = preprocessing.MinMaxScaler()
x_scaled = min_max_scaler.fit_transform(x)
df_1 = pd.DataFrame(x_scaled,columns=df_1.columns)

df_1.describe(include= 'all')

from sklearn import preprocessing
x = df_1.values #returns a numpy array
min_max_scaler = preprocessing.StandardScaler()
x_scaled_std = min_max_scaler.fit_transform(x)
df_1 = pd.DataFrame(x_scaled_std,columns=df_1.columns)

df_1.describe()

df.to_csv("cleaned_assig5.csv",index=False)

"""##Linear Regression

b = sum((x(i) - mean(x)) * (y(i) - mean(y))) / sum( (x(i) - mean(x))^2 )
OR
b = covariance(x,y) / variance(x)
a = mean(y) - b * mean(x)

"""

from math import sqrt

# Calculate root mean squared error
def rmse_metric(actual, predicted):
    sum_error = 0.0
    for i in range(len(actual)):
        prediction_error = predicted[i] - actual[i]
        sum_error += (prediction_error ** 2)
    mean_error = sum_error / float(len(actual))
    return sqrt(mean_error)

from sklearn.linear_model import LinearRegression

# Split data in Training and testing 
from sklearn.model_selection import train_test_split
import numpy as np

train_count = int(df_1.shape[0] * 0.7)
test_count = df_1.shape[0] - train_count
train_count,test_count

Y_train = df_1.iloc[:train_count,19]
Y_test = df_1.iloc[train_count:,19]
Y_train.shape, Y_test.shape

X_train = df_1.iloc[:train_count,[0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18]]
X_test = df_1.iloc[train_count:,[0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18]]
X_train.shape, X_test.shape

reg = LinearRegression().fit(X_train, Y_train)

reg.coef_, reg.intercept_

Y_pred = reg.predict(X_test)

rmse_metric(Y_test.values,Y_pred)

rmse_metric(Y_test.values,Y_pred)/Y_test.mean() * 100